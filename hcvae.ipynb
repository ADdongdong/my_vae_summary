{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这个HCVAE是第一版\n",
    "# 在解码的时候，先计算出来均值和方差，然后再使用重参数化得到其重构误差\n",
    "class HCVAE(nn.Module):\n",
    "    \"\"\"Implementation of CVAE(Conditional Variational Auto-Encoder)\"\"\"\n",
    "\n",
    "    def __init__(self, feature_size, class_size, latent_size):\n",
    "        super(HCVAE, self).__init__()\n",
    "\n",
    "        # 定义均方差对象\n",
    "        self.Loss_MSE = torch.nn.MSELoss()\n",
    "\n",
    "        '''\n",
    "            在这个网络中，对与每一层编码和解码。\n",
    "            都是一个两层的网络结构；先将数据转换为200维度的数据，\n",
    "            然后，将200维度的数据再转换为重构值或者均值方差\n",
    "        '''\n",
    "        # 定义网络\n",
    "        self.fc2_mu = nn.Linear(200, latent_size)\n",
    "        self.fc2_log_std = nn.Linear(200, latent_size)\n",
    "        self.fc1_mu = nn.Linear(200, feature_size)\n",
    "        self.fc1_log_std = nn.Linear(200, feature_size)\n",
    "\n",
    "        # 编码\n",
    "        self.encoder_fc1 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.encoder_fc2 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.encoder_fc3 = nn.Linear(feature_size + class_size, 200)\n",
    "\n",
    "        # 解码\n",
    "        self.decoder_fc1 = nn.Linear(latent_size + class_size, 200)\n",
    "        self.decoder_fc2 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.decoder_fc3 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.decoder_mu = nn.Linear(200, feature_size)\n",
    "        self.decoder_log_std = nn.Linear(200, feature_size)\n",
    "\n",
    "    def encode1_2(self, func, x, y):\n",
    "        # concat features and labels\n",
    "        h1 = F.relu(func(torch.cat([x, y], dim=1)))\n",
    "        mu = self.fc1_mu(h1)\n",
    "        log_std = self.fc1_log_std(h1)\n",
    "        return mu, log_std\n",
    "\n",
    "    def encode3(self, x, y):\n",
    "        h1 = F.relu(self.encoder_fc3(torch.cat([x, y], dim=1)))\n",
    "        mu = self.fc2_mu(h1)\n",
    "        log_std = self.fc2_log_std(h1)\n",
    "        return mu, log_std\n",
    "\n",
    "    def decode1(self, z, y):\n",
    "        # concat latents and labels\n",
    "        h3 = F.relu(self.decoder_fc1(torch.cat([z, y], dim=1)))\n",
    "        # 这里decoder也是先decoder出来均值和方差，因为，后面计算loss函数要用\n",
    "        # 在decoder后再使用reparametrize重采样出来一个z放入下一层解码\n",
    "        de_mu = self.fc1_mu(h3)\n",
    "        de_log_std = self.fc1_log_std(h3)\n",
    "\n",
    "        return de_mu, de_log_std\n",
    "        \n",
    "\n",
    "    def decode2_3(self, z, y):\n",
    "        # concat latents and labels\n",
    "        h3 = F.relu(self.decoder_fc3(torch.cat([z, y], dim=1)))\n",
    "        # 这里decoder也是先decoder出来均值和方差，因为，后面计算loss函数要用\n",
    "        # 在decoder后再使用reparametrize重采样出来一个z放入下一层解码\n",
    "        de_mu = self.fc1_mu(h3)\n",
    "        de_log_std = self.fc1_log_std(h3)\n",
    "        return de_mu, de_log_std\n",
    "\n",
    "    def final_decode(self, z, y):\n",
    "        h3 = F.relu(self.decoder_fc3(torch.cat([z, y], dim=1)))\n",
    "        mu = self.decoder_mu(h3)\n",
    "        log_std = self.decoder_log_std(h3)\n",
    "        return mu, log_std\n",
    "\n",
    "    def reparametrize(self, mu, log_std):\n",
    "        std = torch.exp(log_std)\n",
    "        eps = torch.randn_like(std)  # simple from standard normal distribution\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # 第一次条件编码\n",
    "        mu_1, log_std_1 = self.encode1_2(self.encoder_fc1, x, y)\n",
    "        z_1 = self.reparametrize(mu_1, log_std_1)\n",
    "\n",
    "        # 第二次条件编码\n",
    "        mu_2, log_std_2 = self.encode1_2(self.encoder_fc2, z_1, y)\n",
    "        z2 = self.reparametrize(mu_2, log_std_2)\n",
    "\n",
    "        # 第三次条件编码\n",
    "        mu_3, log_std_3 = self.encode3(z2, y)\n",
    "        z3 = self.reparametrize(mu_3, log_std_3)\n",
    "\n",
    "        # 第一次条件解码\n",
    "        # 先解码出重构值，再根据重构值计算其均值和方差\n",
    "        de_mu3, de_log3 = self.decode1(z3, y)\n",
    "        recon3 = self.reparametrize(de_mu3, de_log3)\n",
    "\n",
    "        # 第二次条件解码\n",
    "        de_mu2, de_log2 = self.decode2_3(recon3, y)\n",
    "        recon2 = self.reparametrize(de_mu2, de_log2)\n",
    "\n",
    "        # 第三次条件解码\n",
    "        de_mu1, de_log1 = self.final_decode(recon2, y)\n",
    "        de_z3 = self.reparametrize(de_mu1, de_log1)\n",
    "\n",
    "        # 根据计算loss函数所用到的内容\n",
    "        # 将编码得到的方差打包成数组\n",
    "        en_log = [log_std_1, log_std_2, log_std_3]\n",
    "        # 将编码和解码得到的均值打包成方差\n",
    "        en_mu = [mu_1, mu_2, mu_3]\n",
    "        de_mu = [de_mu1, de_mu2, de_mu3]\n",
    "\n",
    "        loss = self.loss_function(en_log, en_mu, de_mu)\n",
    "        return loss\n",
    "\n",
    "    def loss_function(self, en_log, en_mu, de_mu) -> torch.Tensor:\n",
    "        # 根据hcvae的loss公式来计算loss函数\n",
    "        # 方差部分为编码器的方差之和\n",
    "        logvar_sum = -torch.sum(torch.log(en_log[0]))\n",
    "        logvar_sum = logvar_sum - torch.sum(torch.log(en_log[1]))\n",
    "        logvar_sum = logvar_sum - torch.sum(torch.log(en_log[2]))\n",
    "        #print('logvar_sum',logvar_sum)\n",
    "\n",
    "        #  均值部分为编码器和解码器d对应的均值的均方差\n",
    "        mu_sum = self.Loss_MSE(en_mu[0], de_mu[1])\n",
    "        mu_sum = mu_sum +  self.Loss_MSE(en_mu[1], de_mu[0])\n",
    "        #print('mu_sum', mu_sum)\n",
    "\n",
    "        # 修改loss函数的计算方式，改成kl散度+重构误差\n",
    "\n",
    "        # 计算整体的loss函数\n",
    "        loss = logvar_sum + mu_sum\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这是第二版HCVAE，第一版的问题是，loss会变成nan值\n",
    "第二版改变了计算loss函数的方式，不用HVAE的均值和方差计算\n",
    "而是使用传统的kl散度和重构误差之和作为loss函数值看看效果\n",
    "'''\n",
    "class HCVAE2(nn.Module):\n",
    "    \"\"\"Implementation of CVAE(Conditional Variational Auto-Encoder)\"\"\"\n",
    "\n",
    "    def __init__(self, feature_size, class_size, latent_size):\n",
    "        super(HCVAE2, self).__init__()\n",
    "\n",
    "        # 定义均方差对象\n",
    "        self.Loss_MSE = torch.nn.MSELoss()\n",
    "\n",
    "        # 定义网络\n",
    "        self.fc2_mu = nn.Linear(200, latent_size)\n",
    "        self.fc2_log_std = nn.Linear(200, latent_size)\n",
    "        self.fc1_mu = nn.Linear(200, feature_size)\n",
    "        self.fc1_log_std = nn.Linear(200, feature_size)\n",
    "        # 编码\n",
    "        self.encoder_fc1 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.encoder_fc2 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.encoder_fc3 = nn.Linear(feature_size + class_size, 200)\n",
    "\n",
    "        # 解码\n",
    "        self.decoder_fc1 = nn.Linear(latent_size + class_size, 200)\n",
    "        self.decoder_fc2 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.decoder_fc3 = nn.Linear(feature_size + class_size, 200)\n",
    "        self.decoder_mu = nn.Linear(200, feature_size)\n",
    "        self.decoder_log_std = nn.Linear(200, feature_size)\n",
    "\n",
    "    def encode1_2(self, func, x, y):\n",
    "        # concat features and labels\n",
    "        h1 = F.relu(func(torch.cat([x, y], dim=1)))\n",
    "        mu = self.fc1_mu(h1)\n",
    "        log_std = self.fc1_log_std(h1)\n",
    "        return mu, log_std\n",
    "\n",
    "    def encode3(self, x, y):\n",
    "        h1 = F.relu(self.encoder_fc3(torch.cat([x, y], dim=1)))\n",
    "        mu = self.fc2_mu(h1)\n",
    "        log_std = self.fc2_log_std(h1)\n",
    "        return mu, log_std\n",
    "\n",
    "    def decode1(self, z, y):\n",
    "        # concat latents and labels\n",
    "        h3 = F.relu(self.decoder_fc1(torch.cat([z, y], dim=1)))\n",
    "        # 这里decoder也是先decoder出来均值和方差，因为，后面计算loss函数要用\n",
    "        # 在decoder后再使用reparametrize重采样出来一个z放入下一层解码\n",
    "        de_mu = self.fc1_mu(h3)\n",
    "        de_log_std = self.fc1_log_std(h3)\n",
    "\n",
    "        return de_mu, de_log_std\n",
    "        \n",
    "\n",
    "    def decode2_3(self, z, y):\n",
    "        # concat latents and labels\n",
    "        h3 = F.relu(self.decoder_fc3(torch.cat([z, y], dim=1)))\n",
    "        # 这里decoder也是先decoder出来均值和方差，因为，后面计算loss函数要用\n",
    "        # 在decoder后再使用reparametrize重采样出来一个z放入下一层解码\n",
    "        de_mu = self.fc1_mu(h3)\n",
    "        de_log_std = self.fc1_log_std(h3)\n",
    "        return de_mu, de_log_std\n",
    "\n",
    "    def final_decode(self, z, y):\n",
    "        h3 = F.relu(self.decoder_fc3(torch.cat([z, y], dim=1)))\n",
    "        mu = self.decoder_mu(h3)\n",
    "        log_std = self.decoder_log_std(h3)\n",
    "        return mu, log_std\n",
    "\n",
    "    def reparametrize(self, mu, log_std):\n",
    "        std = torch.exp(log_std)\n",
    "        eps = torch.randn_like(std)  # simple from standard normal distribution\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # 第一次条件编码\n",
    "        mu_1, log_std_1 = self.encode1_2(self.encoder_fc1, x, y)\n",
    "        z_1 = self.reparametrize(mu_1, log_std_1)\n",
    "\n",
    "        # 第二次条件编码\n",
    "        mu_2, log_std_2 = self.encode1_2(self.encoder_fc2, z_1, y)\n",
    "        z2 = self.reparametrize(mu_2, log_std_2)\n",
    "\n",
    "        # 第三次条件编码\n",
    "        mu_3, log_std_3 = self.encode3(z2, y)\n",
    "        z3 = self.reparametrize(mu_3, log_std_3)\n",
    "\n",
    "        # 第一次条件解码\n",
    "        # 先解码出重构值，再根据重构值计算其均值和方差\n",
    "        de_mu3, de_log3 = self.decode1(z3, y)\n",
    "        recon3 = self.reparametrize(de_mu3, de_log3)\n",
    "\n",
    "        # 第二次条件解码\n",
    "        de_mu2, de_log2 = self.decode2_3(recon3, y)\n",
    "        recon2 = self.reparametrize(de_mu2, de_log2)\n",
    "\n",
    "        # 第三次条件解码\n",
    "        de_mu1, de_log1 = self.final_decode(recon2, y)\n",
    "        recon1 = self.reparametrize(de_mu1, de_log1)\n",
    "\n",
    "        # 根据计算loss函数所用到的内容\n",
    "        # 将编码和解码得到的均值打包成方差\n",
    "        en_mu = [mu_1, mu_2, mu_3]\n",
    "        de_mu = [de_mu3, de_mu2, de_mu1]\n",
    "        log_std = [log_std_1, log_std_2, log_std_3]\n",
    "        recon = [recon1, recon2, recon3]\n",
    "        z = [z_1, z2, z3]\n",
    "\n",
    "        #loss = self.loss_function(recon, x,  en_mu, de_mu, log_std)\n",
    "        return recon, z, en_mu, de_mu, log_std\n",
    "\n",
    "    def loss_function(self, recon, z, x, en_mu, de_mu, log_std) -> torch.Tensor:\n",
    "        # 计算重构误差\n",
    "        recon_loss = F.mse_loss(recon[0], x, reduction=\"sum\") \n",
    "        recon_loss = recon_loss + F.mse_loss(recon[1], z[0], reduction=\"sum\" )\n",
    "        recon_loss = recon_loss + F.mse_loss(recon[2], z[1], reduction=\"sum\" )\n",
    "        # 计算KL散度\n",
    "        kl_loss = torch.pow((en_mu[0] - de_mu[1]), 2)\n",
    "        kl_loss = kl_loss +  torch.pow((en_mu[1] - de_mu[0]), 2)\n",
    "        sum_log = torch.sum(log_std[0])+torch.sum(log_std[1])+torch.sum(log_std[2])\n",
    "        kl_loss = torch.sum(kl_loss) - sum_log\n",
    "        \n",
    "        # 计算整体的loss函数\n",
    "        loss =  kl_loss +recon_loss\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100], Batch[1/600], batch_loss:468443.625000\n",
      "Epoch[1/100], Batch[101/600], batch_loss:226302.187500\n",
      "Epoch[1/100], Batch[201/600], batch_loss:147293.171875\n",
      "Epoch[1/100], Batch[301/600], batch_loss:143559.312500\n",
      "Epoch[1/100], Batch[401/600], batch_loss:142684.875000\n",
      "Epoch[1/100], Batch[501/600], batch_loss:141912.234375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\04_python_project\\04_python_machine_learning\\00_pytorch_project\\06_Project_VI\\03_experiment_demo\\00_apple_dema\\02_CVAE\\hcvae\\hcvae.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     \u001b[39m# save val model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     utils\u001b[39m.\u001b[39msave_model(cvae, \u001b[39m\"\u001b[39m\u001b[39m./model_weights/cvae/cvae_weights.pth\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m test2()\n",
      "\u001b[1;32md:\\04_python_project\\04_python_machine_learning\\00_pytorch_project\\06_Project_VI\\03_experiment_demo\\00_apple_dema\\02_CVAE\\hcvae\\hcvae.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m train_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     img, label \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/04_python_project/04_python_machine_learning/00_pytorch_project/06_Project_VI/03_experiment_demo/00_apple_dema/02_CVAE/hcvae/hcvae.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     inputs \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mreshape(img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39;49mdiv(\u001b[39m255\u001b[39;49m)\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test2():\n",
    "    epochs = 100\n",
    "    batch_size = 100\n",
    "\n",
    "    recon = None\n",
    "    img = None\n",
    "\n",
    "    utils.make_dir(\"./img/cvae\")\n",
    "    utils.make_dir(\"./model_weights/cvae\")\n",
    "\n",
    "    train_data = torchvision.datasets.MNIST(\n",
    "        root='./mnist',\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor(),\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    data_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "    cvae = HCVAE2(feature_size=784, class_size=10, latent_size=10)\n",
    "    #cvae = CVAE(feature_size=784, class_size=10, latent_size=10)\n",
    "\n",
    "    optimizer = torch.optim.Adam(cvae.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        train_loss = 0\n",
    "        i = 0\n",
    "        for batch_id, data in enumerate(data_loader):\n",
    "            img, label = data\n",
    "            inputs = img.reshape(img.shape[0], -1)\n",
    "            y = utils.to_one_hot(label.reshape(-1, 1), num_class=10)\n",
    "            #recon, mu, log_std = cvae(inputs, y)\n",
    "            #loss = cvae.loss_function(recon, inputs, mu, log_std)\n",
    "            recon, z,en_mu, de_mu, log_std = cvae.forward(inputs, y)\n",
    "            loss = cvae.loss_function(recon, z, inputs, en_mu, de_mu, log_std)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            i += 1\n",
    "\n",
    "            if batch_id % 100 == 0:\n",
    "                print(\"Epoch[{}/{}], Batch[{}/{}], batch_loss:{:.6f}\".format(\n",
    "                    epoch+1, epochs, batch_id+1, len(data_loader), loss.item()))\n",
    "\n",
    "        print(\"======>epoch:{},\\t epoch_average_batch_loss:{:.6f}============\".format(\n",
    "            epoch+1, train_loss/i), \"\\n\")\n",
    "\n",
    "        # save imgs\n",
    "        if epoch % 10 == 0:\n",
    "            # 查看图像\n",
    "            imgs = utils.to_img(recon[0].detach())\n",
    "            path = \"./img/hcvae/hepoch{}.png\".format(epoch+1)\n",
    "            torchvision.utils.save_image(imgs, path, nrow=10)\n",
    "            print(\"save:\", path, \"\\n\")\n",
    "\n",
    "    torchvision.utils.save_image(img, \"./img/cvae/raw.png\", nrow=10)\n",
    "    print(\"save raw image:./img/cvae/raw/png\", \"\\n\")\n",
    "\n",
    "    # save val model\n",
    "    utils.save_model(cvae, \"./model_weights/cvae/cvae_weights.pth\")\n",
    "\n",
    "test2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 创建包含10000个一维数组的张量\n",
    "num_samples = 10000\n",
    "input_size = 20\n",
    "data = torch.randn(num_samples, input_size)\n",
    "\n",
    "# 创建神经网络实例\n",
    "net = HCVAE2(feature_size=20, class_size=8, latent_size=4)\n",
    "\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 均方误差损失\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# 迭代训练神经网络\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # 正向传播\n",
    "    outputs = net.forward(data)\n",
    "    \n",
    "    # 生成一个示例的目标数据，这里假设目标数据也是随机生成的\n",
    "    targets = torch.randn(num_samples, 1)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # 反向传播和优化\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 打印损失\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# 训练完成后，您可以使用神经网络进行预测\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "240bc028caeb8b02ff80d8aedfc61caf7a0e4db2770780d40c5b717508bae340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
